{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORU14GVEvr3wcqURK5psNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumaiyaData/Metabolic-Syndrome-detector/blob/main/Metabolic_Syndrome_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "yET8iUH_ggBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6cfc0a2-e376-478b-f5ee-bdda6c68c284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8503118503118503\n",
            "Confusion Matrix:\n",
            " [[276  48]\n",
            " [ 24 133]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.85      0.88       324\n",
            "           1       0.73      0.85      0.79       157\n",
            "\n",
            "    accuracy                           0.85       481\n",
            "   macro avg       0.83      0.85      0.84       481\n",
            "weighted avg       0.86      0.85      0.85       481\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8814968814968815\n",
            "Confusion Matrix:\n",
            " [[302  22]\n",
            " [ 35 122]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.91       324\n",
            "           1       0.85      0.78      0.81       157\n",
            "\n",
            "    accuracy                           0.88       481\n",
            "   macro avg       0.87      0.85      0.86       481\n",
            "weighted avg       0.88      0.88      0.88       481\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 1. Load Library + dataset + Y_dataprofile report\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.pipeline import Pipeline,make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import pickle\n",
        "\n",
        "metabolic_syndrom_original= pd.read_csv(\"/content/Metabolic Syndrome.csv\")\n",
        "metabolic_syndrom= metabolic_syndrom_original.copy()\n",
        "metabolic_syndrom.head()\n",
        "# !pip install ydata-profiling\n",
        "# from ydata_profiling import ProfileReport\n",
        "# profile = ProfileReport(metabolic_syndrom, title=\"Profiling Report\")\n",
        "# profile.to_file(\"metabolic_syndrom_report.html\")\n",
        "\n",
        "#2. Based on correlation decide delete or combine columns because highly related columns represent same things:\n",
        "#\n",
        "metabolic_syndrom = metabolic_syndrom.drop(columns=['seqn'])\n",
        "metabolic_syndrom= metabolic_syndrom.drop(columns=['Albuminuria'])\n",
        "metabolic_syndrom= metabolic_syndrom.drop(columns=['BMI'])\n",
        "metabolic_syndrom.head()\n",
        "\n",
        "#3. Separate features (X) and target (y)\n",
        "\n",
        "X = metabolic_syndrom.drop('MetabolicSyndrome', axis=1)\n",
        "y = metabolic_syndrom['MetabolicSyndrome']\n",
        "\n",
        "#4. Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# 5. impute missing Values\n",
        "\n",
        "transformer1 = ColumnTransformer([\n",
        "    ('impute_marital',SimpleImputer(strategy='most_frequent'),['Marital']),\n",
        "    ('impute_income',SimpleImputer(strategy='median'),['Income']),\n",
        "    ('impute_waistcirc',SimpleImputer(strategy='median'),['WaistCirc'])\n",
        "],remainder='passthrough', verbose_feature_names_out=False)\n",
        "\n",
        "# 6. create outlier transformer\n",
        "class OutlierCapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, method='iqr', multiplier=1.5, columns=None):\n",
        "        self.method = method\n",
        "        self.multiplier = multiplier\n",
        "        self.columns = columns\n",
        "        self.limits_ = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X_df = pd.DataFrame(X)\n",
        "        if self.columns is None:\n",
        "             self.columns = X_df.columns\n",
        "\n",
        "        for col in self.columns:\n",
        "            if self.method == 'iqr':\n",
        "                q1 = X_df[col].quantile(0.25)\n",
        "                q3 = X_df[col].quantile(0.75)\n",
        "                iqr = q3 - q1\n",
        "                lower = q1 - self.multiplier * iqr\n",
        "                upper = q3 + self.multiplier * iqr\n",
        "            elif self.method == 'zscore':\n",
        "                mean = X_df[col].mean()\n",
        "                std = X_df[col].std()\n",
        "                lower = mean - self.multiplier * std\n",
        "                upper = mean + self.multiplier * std\n",
        "            else:\n",
        "                raise ValueError(\"method must be 'iqr' or 'zscore'\")\n",
        "            self.limits_[col] = (lower, upper)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_df = pd.DataFrame(X).copy()\n",
        "        for col, (lower, upper) in self.limits_.items():\n",
        "            X_df[col] = np.clip(X_df[col], lower, upper)\n",
        "        return X_df\n",
        "\n",
        "transformer2 = ColumnTransformer([\n",
        "    ('iqr_outlier', Pipeline([\n",
        "        ('outlier', OutlierCapper(method='iqr', multiplier=1.5))\n",
        "    ]), ['WaistCirc', 'UrAlbCr', 'BloodGlucose','HDL', 'Triglycerides']),\n",
        "\n",
        "    ('zscore_outlier', Pipeline([\n",
        "        ('outlier', OutlierCapper(method='zscore', multiplier=1.5))\n",
        "    ]), ['UricAcid'])\n",
        "], remainder='passthrough',verbose_feature_names_out=False)\n",
        "\n",
        "# Income (no outliers), Age (no outliers)\n",
        "\n",
        "# 7. Encoding\n",
        "transformer3 = ColumnTransformer([\n",
        "    ('ohe_columns',OneHotEncoder(sparse_output=False,drop='first',handle_unknown='ignore'),['Sex','Marital','Race']),\n",
        "],remainder='passthrough', verbose_feature_names_out=False)\n",
        "\n",
        "\n",
        "# 8. Scaling\n",
        "class FlexibleScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.minmax_scaler = MinMaxScaler()\n",
        "        self.standard_scaler = StandardScaler()\n",
        "        self.power_scaler = PowerTransformer(method='yeo-johnson')\n",
        "        self.minmax_cols = []\n",
        "        self.standard_cols = []\n",
        "        self.power_cols = []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X_df = pd.DataFrame(X)\n",
        "\n",
        "        # Find which columns exist in the data\n",
        "        self.minmax_cols = [col for col in ['Age', 'Income'] if col in X_df.columns]\n",
        "        self.standard_cols = [col for col in ['UricAcid', 'HDL', 'WaistCirc'] if col in X_df.columns]\n",
        "        self.power_cols = [col for col in ['UrAlbCr', 'BloodGlucose', 'Triglycerides'] if col in X_df.columns]\n",
        "\n",
        "        # Fit scalers only on columns that exist\n",
        "        if self.minmax_cols:\n",
        "            self.minmax_scaler.fit(X_df[self.minmax_cols])\n",
        "        if self.standard_cols:\n",
        "            self.standard_scaler.fit(X_df[self.standard_cols])\n",
        "        if self.power_cols:\n",
        "            self.power_scaler.fit(X_df[self.power_cols])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_df = pd.DataFrame(X).copy()\n",
        "\n",
        "        # Transform only columns that exist\n",
        "        if self.minmax_cols:\n",
        "            X_df[self.minmax_cols] = self.minmax_scaler.transform(X_df[self.minmax_cols])\n",
        "        if self.standard_cols:\n",
        "            X_df[self.standard_cols] = self.standard_scaler.transform(X_df[self.standard_cols])\n",
        "        if self.power_cols:\n",
        "            X_df[self.power_cols] = self.power_scaler.transform(X_df[self.power_cols])\n",
        "\n",
        "        return X_df\n",
        "\n",
        "# Use FlexibleScaler instead of ColumnTransformer\n",
        "transformer4 = FlexibleScaler()\n",
        "\n",
        "# 9 . Combine preprocessing into one preprocessing pipeline\n",
        "preprocessor = Pipeline([\n",
        "    ('transformer1', transformer1),\n",
        "    ('transformer2', transformer2),\n",
        "    ('transformer3', transformer3),\n",
        "    ('transformer4', transformer4)\n",
        "])\n",
        "\n",
        "# 10. Separate pipelines for each model, cross validation, export\n",
        "#\n",
        "#LogisticRegression\n",
        "pipe_lr = Pipeline([('preprocessing', preprocessor), ('classifier', LogisticRegression(class_weight='balanced'))])\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "y_pred = pipe_lr.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)\n",
        "# cross validation using cross_val_score\n",
        "cross_val_score(pipe_lr, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "# export\n",
        "pickle.dump(pipe_lr,open('pipe.pkl','wb'))\n",
        "\n",
        "# #RandomForestClassifier\n",
        "pipe_rf = Pipeline([('preprocessing', preprocessor),('classifier', RandomForestClassifier(class_weight='balanced'))])\n",
        "pipe_rf.fit(X_train, y_train)\n",
        "y_pred = pipe_rf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)\n",
        "# cross validation using cross_val_score\n",
        "cross_val_score(pipe_rf, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "# Export\n",
        "pickle.dump(pipe_rf,open('piperf.pkl','wb'))\n"
      ]
    }
  ]
}